# -*- coding: utf-8 -*-
"""Building_Graphs_yjyoo.ipynb

Automatically generated by Colab.

Original file is located at
# 기본 그래프 생성

1. State 정의
2. 노드 정의
3. 그래프 정의
4. 그래프 컴파일
5. 그래프 시각화

## State 정의
"""

!pip install langgraph==0.3.18
!pip install langchain-openai==0.3.9
!pip install langchain-community==0.3.20
!pip install langchain-teddynote ==0.3.44

from typing import TypedDict, Annotated, List
from langchain_core.documents import Document
from langgraph.graph.message import add_messages

# State 정의
class GraphState(TypedDict):
  answer: Annotated[List[Document],add_messages]
  context: Annotated[str, "context"]
  question:Annotated[str, "question"]
  binary_score:Annotated[str, "binary score yes or no"]
  messages:Annotated[list,add_messages]

from IPython.display import Image,display
def show_graph(graph):
  try:
    display( Image(graph.get_graph().draw_mermaid_png()))

  except Exception:
    pass

"""## 노드 함수 정의"""

def retrieve(state:GraphState) -> GraphState:
    # retrieve: 검색
    documents = "검색된 문서"
    return GraphState(context = documents)


def re_retrieve() -> GraphState:
    # Query Transform: 쿼리 재작성
    documents = "검색된 문서"
    return GraphState(context = documents)


def llm_gpt_execute(state:GraphState) -> GraphState:
    # LLM 실행
    answer = "GPT 생성된 답변"
    return GraphState(answer = answer)


def llm_claude_execute(state:GraphState) -> GraphState:
    # LLM 실행
    answer = "Claude 의 생성된 답변"
    return GraphState(answer = answer)


def relevance_check(state:GraphState) -> GraphState:
    # Relevance Check: 관련성 확인
    binary_score = "Relevance Score"
    return GraphState(binary_score = binary_score)


def sum_up(state:GraphState) -> GraphState:
    # sum_up: 결과 종합
    answer = "종합된 답변"
    return GraphState(answer = answer)


def search_on_web(state:GraphState) -> GraphState:
    # Search on Web: 웹 검색
    documents = state["context"] = "기존 문서"
    searched_documents = "검색된 문서"
    documents += searched_documents
    return GraphState(context = documents)


def handle_error(state: GraphState) -> GraphState:
    # Error Handling: 에러 처리
    error = "에러 발생"
    return GraphState(context=error)


def decision(state: GraphState) -> GraphState:
    # 의사결정
    decision = "결정"
    # 로직을 추가할 수 가 있고요.

    if state["binary_score"] == "yes":
        return "종료"
    else:
        return "재검색"

"""## 그래프 정의

### Conventional RAG
"""

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# langgraph.graph에서 StateGraph와 END를 가져옵니다.
workflow = StateGraph(GraphState)

# 노드를 추가합니다.
workflow.add_node("retrieve",retrieve)
workflow.add_node("gpt_request",llm_gpt_execute)

# 각 노드들을 연결합니다.
#workflow.add_edge(START,"retrieve") # 시작을 retrieve로 설정할 수 있음
workflow.add_edge("retrieve","gpt_request")
workflow.add_edge("gpt_request",END)

# 시작점을 설정합니다.
workflow.set_entry_point("retrieve")

# 기록을 위한 메모리 저장소를 설정합니다.
memory = MemorySaver()

# 그래프를 컴파일합니다.
app = workflow.compile(checkpointer=memory)


# 그래프 시각화 함수 정의
show_graph(app)

"""### 재검색"""

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# langgraph.graph에서 StateGraph와 END를 가져옵니다.
workflow1 = StateGraph(GraphState)

# 노드를 추가합니다.
workflow1.add_node("retrieve",retrieve)
workflow1.add_node("gpt_request",llm_gpt_execute)
workflow1.add_node("relevance_check",relevance_check)

# 각 노드들을 연결합니다.
workflow1.add_edge("retrieve","relevance_check")
workflow1.add_edge("gpt_request",END)

# 조건부 엣지를 추가합니다. (2), (4)
workflow1.add_conditional_edges(
    "relevance_check",
    decision,
    {"yes":"gpt_request", "no":"retrieve"}
    )


# 시작점을 설정합니다.
workflow1.set_entry_point("retrieve")

# 기록을 위한 메모리 저장소를 설정합니다.
memory = MemorySaver()

# 그래프를 컴파일합니다.
app1 = workflow1.compile(checkpointer=memory)

# 그래프 시각화
show_graph(app1)

"""### Search 추가"""

from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# langgraph.graph에서 StateGraph와 END를 가져옵니다.
workflow2 = StateGraph(GraphState)

# 노드를 추가합니다.
workflow2.add_node("retrieve",retrieve)
workflow2.add_node("relevance_check",relevance_check)
workflow2.add_node("search_on_web",search_on_web)
workflow2.add_node("llm_gpt_execute",llm_gpt_execute)

# 각 노드들을 연결합니다.
workflow2.add_edge("retrieve","relevance_check")
workflow2.add_edge("search_on_web","llm_gpt_execute")
workflow2.add_edge("llm_gpt_execute",END)

# 조건부 엣지를 추가합니다.
workflow2.add_conditional_edges(
    "relevance_check",
    decision,
    {"yes":"llm_gpt_execute", "no":"search_on_web"}
)

# 시작점을 설정합니다.
workflow2.set_entry_point("retrieve")
# 기록을 위한 메모리 저장소를 설정합니다.
memory = MemorySaver()

# 그래프를 컴파일합니다.
app2 = workflow2.compile(checkpointer=memory)

# 그래프 시각화
show_graph(app2)
